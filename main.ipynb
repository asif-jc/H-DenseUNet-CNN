{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "R_tibia_15A\n",
      "Height of Paitent in mm:  1523.5\n",
      "Length of Paitent AOI (tibia) in mm:  314.8372802734375\n",
      "AOI Slice Start:  684\n",
      "AOI Slice End:  893\n",
      "AOI Slice Range:  210\n",
      "Mask Slices Normalized to MRI Scans Shape (Purely AOI):  (210, 512, 512)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing\n",
    "\n",
    "# \\\\files.auckland.ac.nz\\research\\resmed202100086-tws ----> Address for raw data\n",
    "scans_path = 'D:/MRI - Tairawhiti'\n",
    "# filename_labels = ['R_tibia_15A', 'R_tibia_16A', 'R_tibia_4A']\n",
    "filename_labels = ['R_tibia_15A']\n",
    "preprocessed_images, preprocessed_masks = preprocessing(scans_path, filename_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting medpyNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ggpc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ggpc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ggpc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ggpc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ggpc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ggpc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ggpc\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading MedPy-0.4.0.tar.gz (151 kB)\n",
      "     -------------------------------------- 151.8/151.8 kB 3.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\ggpc\\anaconda3\\lib\\site-packages (from medpy) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\ggpc\\anaconda3\\lib\\site-packages (from medpy) (1.23.5)\n",
      "Requirement already satisfied: SimpleITK>=1.1.0 in c:\\users\\ggpc\\anaconda3\\lib\\site-packages (from medpy) (2.2.1)\n",
      "Building wheels for collected packages: medpy\n",
      "  Building wheel for medpy (setup.py): started\n",
      "  Building wheel for medpy (setup.py): finished with status 'done'\n",
      "  Created wheel for medpy: filename=MedPy-0.4.0-py3-none-any.whl size=215881 sha256=8af40144571a17ee2b6c3b866921d606562b44942a374826e152907aa5405b89\n",
      "  Stored in directory: c:\\users\\ggpc\\appdata\\local\\pip\\cache\\wheels\\41\\46\\a2\\7c585b78f216a3dd8723dbab5f439822fa5dfbff563757a49e\n",
      "Successfully built medpy\n",
      "Installing collected packages: medpy\n",
      "Successfully installed medpy-0.4.0\n"
     ]
    }
   ],
   "source": [
    "# %pip install custom_layers\n",
    "%pip install medpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet pretrained DenseNet\n",
    "from preprocessing import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization, Activation, Conv2DTranspose, concatenate\n",
    "from keras.layers.core import Dropout\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Define U-Net model\n",
    "def unet_model(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    # Decoder\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "    \n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "    \n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Dice Coefficient Loss Function \n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return 1.0 - dice\n",
    "\n",
    "\n",
    "# Reformat image data structure\n",
    "training_scans_reshaped = np.concatenate(preprocessed_images, axis=0)\n",
    "training_scans = training_scans_reshaped.reshape((-1, 512, 512, 1))\n",
    "train_mask_tibia_labels_reshaped = np.concatenate(preprocessed_masks, axis=0)\n",
    "train_mask_tibia_labels = train_mask_tibia_labels_reshaped.reshape((-1, 512, 512, 1))\n",
    "\n",
    "# Split the data into training and validation sets\\\n",
    "images_train, images_val, labels_train, labels_val = train_test_split(training_scans, train_mask_tibia_labels, test_size=0.2, random_state=0)\n",
    "unseen_scan_model = np.array(training_scans[2][100])\n",
    "images_train = images_train.astype('float32') / 255.0\n",
    "images_val = images_val.astype('float32') / 255.0\n",
    "\n",
    "print(images_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(images_train.dtype)\n",
    "print(labels_train.dtype)\n",
    "print(images_val.shape)\n",
    "print(labels_val.shape)\n",
    "print(images_val.dtype)\n",
    "print(labels_val.dtype)\n",
    "print(unseen_scan_model.shape)\n",
    "\n",
    "# Expand dimensions for the channel (grayscale) dimension\n",
    "# images_train = np.expand_dims(images_train, axis=-1)\n",
    "# images_val = np.expand_dims(images_val, axis=-1)\n",
    "# labels_train = np.expand_dims(labels_train, axis=-1)\n",
    "# labels_val = np.expand_dims(labels_val, axis=-1)\n",
    "\n",
    "# Create an instance of the U-Net model\n",
    "input_shape = (512, 512, 1)  # For grayscale images\n",
    "\n",
    "# Create an instance of the U-Net model\n",
    "model = unet_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "# Binary Cross Entropy Loss Function\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Dice Coefficient Loss Function\n",
    "# model.compile(optimizer=Adam(), loss=dice_coefficient, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# Hyperparameter tuning -> batch_size\n",
    "model.fit(x=images_train, y=labels_train, batch_size=32, epochs=1, validation_data=(images_val, labels_val))\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x=images_val, y=labels_val)\n",
    "\n",
    "# Perform inference on new, unseen MRI scans\n",
    "predictions = model.predict(unseen_scan_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
