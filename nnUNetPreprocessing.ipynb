{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path # pathlib for easy path handling\n",
    "import pydicom # pydicom to handle dicom files\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import dicom2nifti # to convert DICOM files to the NIftI format\n",
    "import nibabel as nib # nibabel to handle nifti files\n",
    "\n",
    "from typing import Tuple\n",
    "from batchgenerators.utilities.file_and_folder_operations import save_json, join"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dicom2nifti.settings as settings\n",
    "settings.disable_validate_slice_increment()\n",
    "\n",
    "scan_dicom_path = \"/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/MRI Scans - Tairawhiti/15A_AutoBind_WaterWATER_450\"\n",
    "scan_nifti_path = \"/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/MRI Scans - Tairawhiti - Nifti/15A_AutoBind_WaterWATER_450\"\n",
    "mask_path = \"/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/Mask_exports/1_R_tibia_15A.nii\"\n",
    "mask = nib.load(mask_path)\n",
    "\n",
    "\n",
    "dicom2nifti.convert_directory(scan_dicom_path, scan_nifti_path)\n",
    "nib.save(mask, \"/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/Mask_exports - Nifti/1_R_tibia_15A.nii.gz\")\n",
    "\n",
    "\n",
    "#patients_folders = os.listdir(path_to_all_patients)\n",
    "#for patient in patients_folder:\n",
    "#dicom2nifti.convert_directorylos.path.join (path_to_all_patients, patient), os.path.join(k\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dataset json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_json(output_folder: str,\n",
    "                          channel_names: dict,\n",
    "                          labels: dict,\n",
    "                          num_training_cases: int,\n",
    "                          file_ending: str,\n",
    "                          regions_class_order: Tuple[int, ...] = None,\n",
    "                          dataset_name: str = None, reference: str = None, release: str = None, license: str = None,\n",
    "                          description: str = None,\n",
    "                          overwrite_image_reader_writer: str = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generates a dataset.json file in the output folder\n",
    "\n",
    "    channel_names:\n",
    "        Channel names must map the index to the name of the channel, example:\n",
    "        {\n",
    "            0: 'T1',\n",
    "            1: 'CT'\n",
    "        }\n",
    "        Note that the channel names may influence the normalization scheme!! Learn more in the documentation.\n",
    "\n",
    "    labels:\n",
    "        This will tell nnU-Net what labels to expect. Important: This will also determine whether you use region-based training or not.\n",
    "        Example regular labels:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'left atrium': 1,\n",
    "            'some other label': 2\n",
    "        }\n",
    "        Example region-based training:\n",
    "        {\n",
    "            'background': 0,\n",
    "            'whole tumor': (1, 2, 3),\n",
    "            'tumor core': (2, 3),\n",
    "            'enhancing tumor': 3\n",
    "        }\n",
    "\n",
    "        Remember that nnU-Net expects consecutive values for labels! nnU-Net also expects 0 to be background!\n",
    "\n",
    "    num_training_cases: is used to double check all cases are there!\n",
    "\n",
    "    file_ending: needed for finding the files correctly. IMPORTANT! File endings must match between images and\n",
    "    segmentations!\n",
    "\n",
    "    dataset_name, reference, release, license, description: self-explanatory and not used by nnU-Net. Just for\n",
    "    completeness and as a reminder that these would be great!\n",
    "\n",
    "    overwrite_image_reader_writer: If you need a special IO class for your dataset you can derive it from\n",
    "    BaseReaderWriter, place it into nnunet.imageio and reference it here by name\n",
    "\n",
    "    kwargs: whatever you put here will be placed in the dataset.json as well\n",
    "\n",
    "    \"\"\"\n",
    "    has_regions: bool = any([isinstance(i, (tuple, list)) and len(i) > 1 for i in labels.values()])\n",
    "    if has_regions:\n",
    "        assert regions_class_order is not None, f\"You have defined regions but regions_class_order is not set. \" \\\n",
    "                                                f\"You need that.\"\n",
    "    # channel names need strings as keys\n",
    "    keys = list(channel_names.keys())\n",
    "    for k in keys:\n",
    "        if not isinstance(k, str):\n",
    "            channel_names[str(k)] = channel_names[k]\n",
    "            del channel_names[k]\n",
    "\n",
    "    # labels need ints as values\n",
    "    for l in labels.keys():\n",
    "        value = labels[l]\n",
    "        if isinstance(value, (tuple, list)):\n",
    "            value = tuple([int(i) for i in value])\n",
    "            labels[l] = value\n",
    "        else:\n",
    "            labels[l] = int(labels[l])\n",
    "\n",
    "    dataset_json = {\n",
    "        'channel_names': channel_names,  # previously this was called 'modality'. I didnt like this so this is\n",
    "        # channel_names now. Live with it.\n",
    "        'labels': labels,\n",
    "        'numTraining': num_training_cases,\n",
    "        'file_ending': file_ending,\n",
    "    }\n",
    "\n",
    "    if dataset_name is not None:\n",
    "        dataset_json['name'] = dataset_name\n",
    "    if reference is not None:\n",
    "        dataset_json['reference'] = reference\n",
    "    if release is not None:\n",
    "        dataset_json['release'] = release\n",
    "    if license is not None:\n",
    "        dataset_json['licence'] = license\n",
    "    if description is not None:\n",
    "        dataset_json['description'] = description\n",
    "    if overwrite_image_reader_writer is not None:\n",
    "        dataset_json['overwrite_image_reader_writer'] = overwrite_image_reader_writer\n",
    "    if regions_class_order is not None:\n",
    "        dataset_json['regions_class_order'] = regions_class_order\n",
    "\n",
    "    dataset_json.update(kwargs)\n",
    "\n",
    "    save_json(dataset_json, join(output_folder, 'dataset.json'), sort_keys=False)\n",
    "\n",
    "\n",
    "#generate_dataset_json(output_folder: str, channel_names: dict, labels: dict, num_training_cases: int, file_ending: str, regions_class_order: Tuple[int, ...] = None, dataset_name: str = None, reference: str = None, release: str = None, license: str = None, description: str = None, overwrite_image_reader_writer: str = None, **kwargs):\n",
    "\n",
    "generate_dataset_json(output_folder = \"/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/nnUnet/dataset_json\",\n",
    "                          channel_names = {\n",
    "                                            0: 'MRI'\n",
    "                                        },\n",
    "                          labels = {\n",
    "                                        'background': 0,\n",
    "                                        'tibia': 1,\n",
    "                                    },\n",
    "                          num_training_cases = 1,\n",
    "                          file_ending = \".nii.gz\",\n",
    "                          regions_class_order = None,\n",
    "                          dataset_name = None, reference = None, release = None, license = None,\n",
    "                          description = None,\n",
    "                          overwrite_image_reader_writer = None)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
