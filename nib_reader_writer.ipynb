{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:294: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:294: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "/var/folders/cs/cg0d4rbx47b47cfl52bxrdtc0000gn/T/ipykernel_24654/834280432.py:294: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  images_r, dct_r = nibio_r.read_images([img_file][1,:,:,:])\n",
      "/var/folders/cs/cg0d4rbx47b47cfl52bxrdtc0000gn/T/ipykernel_24654/834280432.py:294: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  images_r, dct_r = nibio_r.read_images([img_file][1,:,:,:])\n",
      "/var/folders/cs/cg0d4rbx47b47cfl52bxrdtc0000gn/T/ipykernel_24654/834280432.py:294: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  images_r, dct_r = nibio_r.read_images([img_file][1,:,:,:])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 294\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39m# nibio = NibabelIO()\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# images, dct = nibio.read_images([img_file])\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m# seg, dctseg = nibio.read_seg(seg_file)\u001b[39;00m\n\u001b[1;32m    293\u001b[0m nibio_r \u001b[39m=\u001b[39m NibabelIOWithReorient()\n\u001b[0;32m--> 294\u001b[0m images_r, dct_r \u001b[39m=\u001b[39m nibio_r\u001b[39m.\u001b[39mread_images([img_file][\u001b[39m1\u001b[39;49m,:,:,:])\n\u001b[1;32m    295\u001b[0m seg_r, dctseg_r \u001b[39m=\u001b[39m nibio_r\u001b[39m.\u001b[39mread_seg(seg_file[\u001b[39m1\u001b[39m,:,:,:])\n\u001b[1;32m    297\u001b[0m \u001b[39m#nibio.write_seg(seg[0], '/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/nibio_read_write/seg_nibio.nii.gz', dctseg)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "#    Copyright 2021 HIP Applied Computer Vision Lab, Division of Medical Image Computing, German Cancer Research Center\n",
    "#    (DKFZ), Heidelberg, Germany\n",
    "#\n",
    "#    Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#    you may not use this file except in compliance with the License.\n",
    "#    You may obtain a copy of the License at\n",
    "#\n",
    "#        http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#    Unless required by applicable law or agreed to in writing, software\n",
    "#    distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#    See the License for the specific language governing permissions and\n",
    "#    limitations under the License.\n",
    "\n",
    "from typing import Tuple, Union, List\n",
    "import numpy as np\n",
    "from nibabel import io_orientation\n",
    "import nibabel\n",
    "\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Tuple, Union, List\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BaseReaderWriter(ABC):\n",
    "    @staticmethod\n",
    "    def _check_all_same(input_list):\n",
    "        # compare all entries to the first\n",
    "        for i in input_list[1:]:\n",
    "            if not len(i) == len(input_list[0]):\n",
    "                return False\n",
    "            all_same = all(i[j] == input_list[0][j] for j in range(len(i)))\n",
    "            if not all_same:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_all_same_array(input_list):\n",
    "        # compare all entries to the first\n",
    "        for i in input_list[1:]:\n",
    "            if not all([a == b for a, b in zip(i.shape, input_list[0].shape)]):\n",
    "                return False\n",
    "            all_same = np.allclose(i, input_list[0])\n",
    "            if not all_same:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    @abstractmethod\n",
    "    def read_images(self, image_fnames: Union[List[str], Tuple[str, ...]]) -> Tuple[np.ndarray, dict]:\n",
    "        \"\"\"\n",
    "        Reads a sequence of images and returns a 4d (!) np.ndarray along with a dictionary. The 4d array must have the\n",
    "        modalities (or color channels, or however you would like to call them) in its first axis, followed by the\n",
    "        spatial dimensions (so shape must be c,x,y,z where c is the number of modalities (can be 1)).\n",
    "        Use the dictionary to store necessary meta information that is lost when converting to numpy arrays, for\n",
    "        example the Spacing, Orientation and Direction of the image. This dictionary will be handed over to write_seg\n",
    "        for exporting the predicted segmentations, so make sure you have everything you need in there!\n",
    "\n",
    "        IMPORTANT: dict MUST have a 'spacing' key with a tuple/list of length 3 with the voxel spacing of the np.ndarray.\n",
    "        Example: my_dict = {'spacing': (3, 0.5, 0.5), ...}. This is needed for planning and\n",
    "        preprocessing. The ordering of the numbers must correspond to the axis ordering in the returned numpy array. So\n",
    "        if the array has shape c,x,y,z and the spacing is (a,b,c) then a must be the spacing of x, b the spacing of y\n",
    "        and c the spacing of z.\n",
    "\n",
    "        In the case of 2D images, the returned array should have shape (c, 1, x, y) and the spacing should be\n",
    "        (999, sp_x, sp_y). Make sure 999 is larger than sp_x and sp_y! Example: shape=(3, 1, 224, 224),\n",
    "        spacing=(999, 1, 1)\n",
    "\n",
    "        For images that don't have a spacing, set the spacing to 1 (2d exception with 999 for the first axis still applies!)\n",
    "\n",
    "        :param image_fnames:\n",
    "        :return:\n",
    "            1) a np.ndarray of shape (c, x, y, z) where c is the number of image channels (can be 1) and x, y, z are\n",
    "            the spatial dimensions (set x=1 for 2D! Example: (3, 1, 224, 224) for RGB image).\n",
    "            2) a dictionary with metadata. This can be anything. BUT it HAS to inclue a {'spacing': (a, b, c)} where a\n",
    "            is the spacing of x, b of y and c of z! If an image doesn't have spacing, just set this to 1. For 2D, set\n",
    "            a=999 (largest spacing value! Make it larger than b and c)\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def read_seg(self, seg_fname: str) -> Tuple[np.ndarray, dict]:\n",
    "        \"\"\"\n",
    "        Same requirements as BaseReaderWriter.read_image. Returned segmentations must have shape 1,x,y,z. Multiple\n",
    "        segmentations are not (yet?) allowed\n",
    "\n",
    "        If images and segmentations can be read the same way you can just `return self.read_image((image_fname,))`\n",
    "        :param seg_fname:\n",
    "        :return:\n",
    "            1) a np.ndarray of shape (1, x, y, z) where x, y, z are\n",
    "            the spatial dimensions (set x=1 for 2D! Example: (1, 1, 224, 224) for 2D segmentation).\n",
    "            2) a dictionary with metadata. This can be anything. BUT it HAS to inclue a {'spacing': (a, b, c)} where a\n",
    "            is the spacing of x, b of y and c of z! If an image doesn't have spacing, just set this to 1. For 2D, set\n",
    "            a=999 (largest spacing value! Make it larger than b and c)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def write_seg(self, seg: np.ndarray, output_fname: str, properties: dict) -> None:\n",
    "        \"\"\"\n",
    "        Export the predicted segmentation to the desired file format. The given seg array will have the same shape and\n",
    "        orientation as the corresponding image data, so you don't need to do any resampling or whatever. Just save :-)\n",
    "\n",
    "        properties is the same dictionary you created during read_images/read_seg so you can use the information here\n",
    "        to restore metadata\n",
    "\n",
    "        IMPORTANT: Segmentations are always 3D! If your input images were 2d then the segmentation will have shape\n",
    "        1,x,y. You need to catch that and export accordingly (for 2d images you need to convert the 3d segmentation\n",
    "        to 2d via seg = seg[0])!\n",
    "\n",
    "        :param seg: A segmentation (np.ndarray, integer) of shape (x, y, z). For 2D segmentations this will be (1, y, z)!\n",
    "        :param output_fname:\n",
    "        :param properties: the dictionary that you created in read_images (the ones this segmentation is based on).\n",
    "        Use this to restore metadata\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class NibabelIO(BaseReaderWriter):\n",
    "    \"\"\"\n",
    "    Nibabel loads the images in a different order than sitk. We convert the axes to the sitk order to be\n",
    "    consistent. This is of course considered properly in segmentation export as well.\n",
    "\n",
    "    IMPORTANT: Run nnUNet_plot_dataset_pngs to verify that this did not destroy the alignment of data and seg!\n",
    "    \"\"\"\n",
    "    supported_file_endings = [\n",
    "        '.nii.gz',\n",
    "        '.nrrd',\n",
    "        '.mha'\n",
    "    ]\n",
    "\n",
    "    def read_images(self, image_fnames: Union[List[str], Tuple[str, ...]]) -> Tuple[np.ndarray, dict]:\n",
    "        images = []\n",
    "        original_affines = []\n",
    "\n",
    "        spacings_for_nnunet = []\n",
    "        for f in image_fnames:\n",
    "            nib_image = nibabel.load(f)\n",
    "            assert len(nib_image.shape) == 3, 'only 3d images are supported by NibabelIO'\n",
    "            original_affine = nib_image.affine\n",
    "\n",
    "            original_affines.append(original_affine)\n",
    "\n",
    "            # spacing is taken in reverse order to be consistent with SimpleITK axis ordering (confusing, I know...)\n",
    "            spacings_for_nnunet.append(\n",
    "                    [float(i) for i in nib_image.header.get_zooms()[::-1]]\n",
    "            )\n",
    "\n",
    "            # transpose image to be consistent with the way SimpleITk reads images. Yeah. Annoying.\n",
    "            images.append(nib_image.get_fdata().transpose((2, 1, 0))[None])\n",
    "\n",
    "        if not self._check_all_same([i.shape for i in images]):\n",
    "            print('ERROR! Not all input images have the same shape!')\n",
    "            print('Shapes:')\n",
    "            print([i.shape for i in images])\n",
    "            print('Image files:')\n",
    "            print(image_fnames)\n",
    "            raise RuntimeError()\n",
    "        if not self._check_all_same_array(original_affines):\n",
    "            print('WARNING! Not all input images have the same original_affines!')\n",
    "            print('Affines:')\n",
    "            print(original_affines)\n",
    "            print('Image files:')\n",
    "            print(image_fnames)\n",
    "            print('It is up to you to decide whether that\\'s a problem. You should run nnUNet_plot_dataset_pngs to verify '\n",
    "                  'that segmentations and data overlap.')\n",
    "        if not self._check_all_same(spacings_for_nnunet):\n",
    "            print('ERROR! Not all input images have the same spacing_for_nnunet! This might be caused by them not '\n",
    "                  'having the same affine')\n",
    "            print('spacings_for_nnunet:')\n",
    "            print(spacings_for_nnunet)\n",
    "            print('Image files:')\n",
    "            print(image_fnames)\n",
    "            raise RuntimeError()\n",
    "\n",
    "        stacked_images = np.vstack(images)\n",
    "        dict = {\n",
    "            'nibabel_stuff': {\n",
    "                'original_affine': original_affines[0],\n",
    "            },\n",
    "            'spacing': spacings_for_nnunet[0]\n",
    "        }\n",
    "        return stacked_images.astype(np.float32), dict\n",
    "\n",
    "    def read_seg(self, seg_fname: str) -> Tuple[np.ndarray, dict]:\n",
    "        return self.read_images((seg_fname, ))\n",
    "\n",
    "    def write_seg(self, seg: np.ndarray, output_fname: str, properties: dict) -> None:\n",
    "        # revert transpose\n",
    "        seg = seg.transpose((2, 1, 0)).astype(np.uint8)\n",
    "        seg_nib = nibabel.Nifti1Image(seg, affine=properties['nibabel_stuff']['original_affine'])\n",
    "        nibabel.save(seg_nib, output_fname)\n",
    "\n",
    "\n",
    "class NibabelIOWithReorient(BaseReaderWriter):\n",
    "    \"\"\"\n",
    "    Reorients images to RAS\n",
    "\n",
    "    Nibabel loads the images in a different order than sitk. We convert the axes to the sitk order to be\n",
    "    consistent. This is of course considered properly in segmentation export as well.\n",
    "\n",
    "    IMPORTANT: Run nnUNet_plot_dataset_pngs to verify that this did not destroy the alignment of data and seg!\n",
    "    \"\"\"\n",
    "    supported_file_endings = [\n",
    "        '.nii.gz',\n",
    "        '.nrrd',\n",
    "        '.mha'\n",
    "    ]\n",
    "\n",
    "    def read_images(self, image_fnames: Union[List[str], Tuple[str, ...]]) -> Tuple[np.ndarray, dict]:\n",
    "        images = []\n",
    "        original_affines = []\n",
    "        reoriented_affines = []\n",
    "\n",
    "        spacings_for_nnunet = []\n",
    "        for f in image_fnames:\n",
    "            nib_image = nibabel.load(f)\n",
    "            assert len(nib_image.shape) == 3, 'only 3d images are supported by NibabelIO'\n",
    "            original_affine = nib_image.affine\n",
    "            reoriented_image = nib_image.as_reoriented(io_orientation(original_affine))\n",
    "            reoriented_affine = reoriented_image.affine\n",
    "\n",
    "            original_affines.append(original_affine)\n",
    "            reoriented_affines.append(reoriented_affine)\n",
    "\n",
    "            # spacing is taken in reverse order to be consistent with SimpleITK axis ordering (confusing, I know...)\n",
    "            spacings_for_nnunet.append(\n",
    "                    [float(i) for i in reoriented_image.header.get_zooms()[::-1]]\n",
    "            )\n",
    "\n",
    "            # transpose image to be consistent with the way SimpleITk reads images. Yeah. Annoying.\n",
    "            images.append(reoriented_image.get_fdata().transpose((2, 1, 0))[None])\n",
    "\n",
    "        if not self._check_all_same([i.shape for i in images]):\n",
    "            print('ERROR! Not all input images have the same shape!')\n",
    "            print('Shapes:')\n",
    "            print([i.shape for i in images])\n",
    "            print('Image files:')\n",
    "            print(image_fnames)\n",
    "            raise RuntimeError()\n",
    "        if not self._check_all_same_array(reoriented_affines):\n",
    "            print('WARNING! Not all input images have the same reoriented_affines!')\n",
    "            print('Affines:')\n",
    "            print(reoriented_affines)\n",
    "            print('Image files:')\n",
    "            print(image_fnames)\n",
    "            print('It is up to you to decide whether that\\'s a problem. You should run nnUNet_plot_dataset_pngs to verify '\n",
    "                  'that segmentations and data overlap.')\n",
    "        if not self._check_all_same(spacings_for_nnunet):\n",
    "            print('ERROR! Not all input images have the same spacing_for_nnunet! This might be caused by them not '\n",
    "                  'having the same affine')\n",
    "            print('spacings_for_nnunet:')\n",
    "            print(spacings_for_nnunet)\n",
    "            print('Image files:')\n",
    "            print(image_fnames)\n",
    "            raise RuntimeError()\n",
    "\n",
    "        stacked_images = np.vstack(images)\n",
    "        dict = {\n",
    "            'nibabel_stuff': {\n",
    "                'original_affine': original_affines[0],\n",
    "                'reoriented_affine': reoriented_affines[0],\n",
    "            },\n",
    "            'spacing': spacings_for_nnunet[0]\n",
    "        }\n",
    "        return stacked_images.astype(np.float32), dict\n",
    "\n",
    "    def read_seg(self, seg_fname: str) -> Tuple[np.ndarray, dict]:\n",
    "        return self.read_images((seg_fname, ))\n",
    "\n",
    "    def write_seg(self, seg: np.ndarray, output_fname: str, properties: dict) -> None:\n",
    "        # revert transpose\n",
    "        seg = seg.transpose((2, 1, 0)).astype(np.uint8)\n",
    "\n",
    "        seg_nib = nibabel.Nifti1Image(seg, affine=properties['nibabel_stuff']['reoriented_affine'])\n",
    "        seg_nib_reoriented = seg_nib.as_reoriented(io_orientation(properties['nibabel_stuff']['original_affine']))\n",
    "        assert np.allclose(properties['nibabel_stuff']['original_affine'], seg_nib_reoriented.affine), \\\n",
    "            'restored affine does not match original affine'\n",
    "        nibabel.save(seg_nib_reoriented, output_fname)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    img_file = '/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/MRI Scans - Tairawhiti - Nifti/15A_AutoBind_WaterWATER_450.nii.gz'\n",
    "    seg_file = \"/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/Mask_exports - Nifti/1_R_tibia_15A.nii.gz\"\n",
    "\n",
    "    # nibio = NibabelIO()\n",
    "    # images, dct = nibio.read_images([img_file])\n",
    "    # seg, dctseg = nibio.read_seg(seg_file)\n",
    "\n",
    "    nibio_r = NibabelIOWithReorient()\n",
    "    images_r, dct_r = nibio_r.read_images([img_file][1,:,:,:])\n",
    "    seg_r, dctseg_r = nibio_r.read_seg(seg_file[1,:,:,:])\n",
    "\n",
    "    #nibio.write_seg(seg[0], '/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/nibio_read_write/seg_nibio.nii.gz', dctseg)\n",
    "    nibio_r.write_seg(seg_r[0], '/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/nibio_read_write/seg_nibio_r.nii.gz', dctseg_r)\n",
    "\n",
    "    s_orig = nibabel.load(seg_file).get_fdata()\n",
    "    #s_nibio = nibabel.load('/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/nibio_read_write/seg_nibio.nii.gz').get_fdata()\n",
    "    s_nibio_r = nibabel.load('/Users/pranavrao/Library/CloudStorage/OneDrive-TheUniversityofAuckland/Part4Project/nibio_read_write/seg_nibio_r.nii.gz').get_fdata()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
